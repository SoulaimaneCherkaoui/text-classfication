{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "725d602e-d05d-4995-ad27-33d856f44739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f160e22f-deb0-4b41-85dc-08fbe93e1395",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv('combined_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d9b36a0-f06c-484b-828b-53eedef632b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ounce feather bowl hummingbird opec moment ala...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>wulvob get your medircations online qnb ikud v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>computer connection from cnn com wednesday es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>university degree obtain a prosperous future m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>thanks for all your answers guys i know i shou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      1  ounce feather bowl hummingbird opec moment ala...\n",
       "1      1  wulvob get your medircations online qnb ikud v...\n",
       "2      0   computer connection from cnn com wednesday es...\n",
       "3      1  university degree obtain a prosperous future m...\n",
       "4      0  thanks for all your answers guys i know i shou..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4f44e3c-62e1-4343-ba77-7078afe5399d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43910\n",
      "39538\n"
     ]
    }
   ],
   "source": [
    "no_spam = dataset[dataset['label'] == 0]\n",
    "spam = dataset[dataset['label'] == 1]\n",
    "\n",
    "# to see if there are bias or not\n",
    "num_spam = len(spam)\n",
    "num_no_spam = len(no_spam)\n",
    "print(num_spam)\n",
    "print(num_no_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1859290-68c6-4bd5-becc-c4b239b73804",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Soulaimane\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Soulaimane\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Soulaimane\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Télécharger les stopwords et lemmatizers si ce n'est pas déjà fait\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialiser le lemmatizer et les stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))  # Vous pouvez changer la langue si nécessaire\n",
    "\n",
    "\n",
    "def to_lowercase(text):\n",
    "    \"\"\"Convertit le texte en minuscules.\"\"\"\n",
    "    return text.lower()\n",
    "\n",
    "\n",
    "def remove_non_alphanumeric(text):\n",
    "    \"\"\"Supprime les caractères non-alphanumériques du texte.\"\"\"\n",
    "    return re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "\n",
    "def remove_urls_mentions_hashtags(text):\n",
    "    \"\"\"Supprime les URLs, mentions et hashtags du texte.\"\"\"\n",
    "    text = re.sub(r'http\\S+', '', text)  # Supprime les URLs\n",
    "    text = re.sub(r'@\\w+', '', text)     # Supprime les mentions\n",
    "    text = re.sub(r'#\\w+', '', text)     # Supprime les hashtags\n",
    "    return text\n",
    "\n",
    "\n",
    "def correct_spelling(text):\n",
    "    \"\"\"Corrige l'orthographe à l'aide de TextBlob.\"\"\"\n",
    "    return str(TextBlob(text).correct())\n",
    "\n",
    "\n",
    "def tokenize_text(text):\n",
    "    \"\"\"Tokenise le texte en mots individuels.\"\"\"\n",
    "    return word_tokenize(text)\n",
    "\n",
    "\n",
    "def remove_stopwords_and_lemmatize(tokens):\n",
    "    \"\"\"Supprime les stopwords et applique la lemmatisation.\"\"\"\n",
    "    return [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Pipeline de prétraitement du texte.\"\"\"\n",
    "    text = to_lowercase(text)\n",
    "    text = remove_non_alphanumeric(text)\n",
    "    text = remove_urls_mentions_hashtags(text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Appliquer le prétraitement à la colonne 'text' de votre dataset\n",
    "dataset['text'] = dataset['text'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69b1a48c-679f-4b10-9e47-036eb82002fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ounce feather bowl hummingbird opec moment ala...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>wulvob get your medircations online qnb ikud v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>computer connection from cnn com wednesday es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>university degree obtain a prosperous future m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>thanks for all your answers guys i know i shou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      1  ounce feather bowl hummingbird opec moment ala...\n",
       "1      1  wulvob get your medircations online qnb ikud v...\n",
       "2      0   computer connection from cnn com wednesday es...\n",
       "3      1  university degree obtain a prosperous future m...\n",
       "4      0  thanks for all your answers guys i know i shou..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d9aebf5-8af6-4889-af4a-adde90947249",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_text2(text):\n",
    "    tokens = tokenize_text(text)\n",
    "    tokens = remove_stopwords_and_lemmatize(tokens)\n",
    "    \n",
    "    # Joindre les tokens en une seule chaîne de texte\n",
    "    processed_text = ' '.join(tokens)\n",
    "    return processed_text\n",
    "\n",
    "# Appliquer la fonction `preprocess_text2` sur la colonne 'text' du dataset\n",
    "dataset['text'] = dataset['text'].apply(preprocess_text2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67b90bc6-b859-4544-b9c4-5b0b5c9bbf18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83448, 10000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialiser le vectoriseur avec des paramètres personnalisés\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=10000,        \n",
    "    max_df=0.8,                 # Exclure les termes apparaissant dans plus de 70% des documents\n",
    "         # Appliquer une transformation logarithmique sur la fréquence des termes\n",
    ")\n",
    "\n",
    "# Appliquer le vectoriseur sur la colonne 'content'\n",
    "X = vectorizer.fit_transform(dataset['text'])\n",
    "\n",
    "# Afficher la dimension du tableau résultant\n",
    "print(X.shape)  # (nombre d'échantillons, nombre de features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4551a244-79d2-4332-9f61-8b6939e92152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle Naive Bayes: 96.99%\n",
      "Précision du modèle Naive Bayes train: 97.04%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "y = dataset['label']  # Sentiments associés aux tweets (0 ou 1)\n",
    "\n",
    "# Diviser les données en ensemble d'entraînement et de test (80% entraînement, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# Initialiser le classificateur Naive Bayes\n",
    "model = MultinomialNB()\n",
    "\n",
    "# Entraîner le modèle sur les données d'entraînement\n",
    "model.fit(X_train, y_train)\n",
    "# Faire des prédictions sur les données de test\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred2 = model.predict(X_train)\n",
    "\n",
    "# Calculer la précision du modèle\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy2 = accuracy_score(y_train, y_pred2)\n",
    "\n",
    "print(f'Précision du modèle Naive Bayes: {accuracy * 100:.2f}%')\n",
    "print(f'Précision du modèle Naive Bayes train: {accuracy2 * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca36f8ca-ca93-490d-826f-a16caeacb93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle Logistic Regression: 98.43%\n",
      "Précision du modèle Logistic Regression train: 98.75%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Initialiser la régression logistique avec une régularisation bayésienne (C est l'inverse de la régularisation)\n",
    "model = LogisticRegression(C=1.01, solver='lbfgs', max_iter=10000)\n",
    "\n",
    "# Entraîner le modèle sur les données d'entraînement\n",
    "model.fit(X_train, y_train)\n",
    "# Faire des prédictions sur les données de test\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred2 = model.predict(X_train)\n",
    "\n",
    "# Calculer la précision du modèle\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy2 = accuracy_score(y_train, y_pred2)\n",
    "\n",
    "print(f'Précision du modèle Logistic Regression: {accuracy * 100:.2f}%')\n",
    "print(f'Précision du modèle Logistic Regression train: {accuracy2 * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0636ce3a-0fe3-431e-a955-0b1a9edcd1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision moyenne du modèle (cross-validation): 98.23% ± 0.18%\n",
      "Précision du modèle Logistic Regression sur test: 98.43%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialiser la régression logistique avec une régularisation bayésienne (C est l'inverse de la régularisation)\n",
    "model = LogisticRegression(C=1.01, solver='lbfgs', max_iter=10000)\n",
    "\n",
    "# Entraîner le modèle sur les données d'entraînement avec validation croisée\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=10)  # Utilisez 5 plis pour la validation croisée\n",
    "\n",
    "# Calculer la précision moyenne de la validation croisée\n",
    "mean_cv_accuracy = cv_scores.mean()\n",
    "std_cv_accuracy = cv_scores.std() \n",
    "\n",
    "# Entraîner le modèle sur l'ensemble des données d'entraînement\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Faire des prédictions sur les données de test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculer la précision du modèle sur les données de test\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Précision moyenne du modèle (cross-validation): {mean_cv_accuracy * 100:.2f}% ± {std_cv_accuracy * 100:.2f}%')\n",
    "print(f'Précision du modèle Logistic Regression sur test: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5cb98972-8dee-4e3f-b67d-c9ef86d86acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle SVM sur test: 98.71%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialiser le modèle SVM\n",
    "model = SVC(kernel='linear', C=1.0)  # Adjust the kernel and hyperparameters as needed\n",
    "\n",
    "# Entraîner le modèle sur les données d'entraînement\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Faire des prédictions sur les données de test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculer la précision du modèle sur les données de test\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Précision du modèle SVM sur test: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70bb2fce-0c71-40ed-9eba-f22104e7106e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle SVM sur train: 99.35%\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_train)\n",
    "\n",
    "# Calculer la précision du modèle sur les données de test\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "\n",
    "print(f'Précision du modèle SVM sur train: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc1a67f-c871-4752-8a30-68f5bb82a3a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
