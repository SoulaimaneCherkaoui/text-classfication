{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81b2f6ea-ca25-41d3-b696-fb67ac113e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8b9e1776-2794-4a1c-a776-5b09660c726a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv('tweet_emotions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ca04430f-3324-46e7-8b0d-aebf1052017a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment                                            content\n",
       "0  1956967341       empty  @tiffanylue i know  i was listenin to bad habi...\n",
       "1  1956967666     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2  1956967696     sadness                Funeral ceremony...gloomy friday...\n",
       "3  1956967789  enthusiasm               wants to hang out with friends SOON!\n",
       "4  1956968416     neutral  @dannycastillo We want to trade with someone w..."
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "beec7061-2a7d-415e-9f83-25599a41524f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['empty', 'sadness', 'enthusiasm', 'neutral', 'worry', 'surprise',\n",
       "       'love', 'fun', 'hate', 'happiness', 'boredom', 'relief', 'anger'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cd68eb8f-bf8f-49e0-b289-4776d7ce760a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1956968487</td>\n",
       "      <td>sadness</td>\n",
       "      <td>I should be sleep, but im not! thinking about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1956969035</td>\n",
       "      <td>sadness</td>\n",
       "      <td>@charviray Charlene my love. I miss you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1956969172</td>\n",
       "      <td>sadness</td>\n",
       "      <td>@kelcouch I'm sorry  at least it's Friday?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id sentiment                                            content\n",
       "1  1956967666   sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2  1956967696   sadness                Funeral ceremony...gloomy friday...\n",
       "6  1956968487   sadness  I should be sleep, but im not! thinking about ...\n",
       "8  1956969035   sadness            @charviray Charlene my love. I miss you\n",
       "9  1956969172   sadness         @kelcouch I'm sorry  at least it's Friday?"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions_to_keep = ['happiness', 'sadness']\n",
    "\n",
    "# Filter the dataset to keep only rows where 'sentiment' is either 'happy' or 'sad'\n",
    "df = dataset[dataset['sentiment'].isin(emotions_to_keep)]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7ebc00ac-2549-4165-8b72-65f342c37147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10374, 3)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8b260256-e870-4975-9369-d3c8d71f0e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5165\n",
      "5209\n"
     ]
    }
   ],
   "source": [
    "sad = df[df['sentiment'] == 'sadness']\n",
    "happy = df[df['sentiment'] == 'happiness']\n",
    "\n",
    "# to see if there are bias or not\n",
    "num_sad = len(sad)\n",
    "num_happy = len(happy)\n",
    "print(num_sad)\n",
    "print(num_happy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d9f8794b-6f4a-4e60-accb-bebe227f137c",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\"tweet_id\"]\n",
    "\n",
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3a4e6e03-99ce-4ca9-b60c-e777bb1ddc74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valeurs uniques :\n",
      "Index(['sadness', 'happiness'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df['sentiment'], uniques = pd.factorize(df['sentiment'])\n",
    "\n",
    "# Afficher les valeurs uniques et le DataFrame\n",
    "print(\"Valeurs uniques :\")\n",
    "print(uniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "af515516-88b8-4b83-a26b-8d73033a5e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>I should be sleep, but im not! thinking about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>@charviray Charlene my love. I miss you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>@kelcouch I'm sorry  at least it's Friday?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            content\n",
       "1          0  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2          0                Funeral ceremony...gloomy friday...\n",
       "6          0  I should be sleep, but im not! thinking about ...\n",
       "8          0            @charviray Charlene my love. I miss you\n",
       "9          0         @kelcouch I'm sorry  at least it's Friday?"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0b0c883a-7c04-4ec1-a107-7348ec4a47b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import re\\nimport nltk\\nfrom nltk.corpus import stopwords\\n\\n# Si ce n'est pas déjà fait, télécharger les stopwords de NLTK\\nnltk.download('stopwords')\\nstop_words = set(stopwords.words('english'))  # Utilise le français si les tweets sont en français, sinon 'english'\\n\\n# Fonction de prétraitement du texte\\ndef preprocess_tweet(text):\\n    # Convertir en minuscules\\n    text = text.lower()\\n    # Supprimer les URL\\n    text = re.sub(r'http\\\\S+|www\\\\S+|https\\\\S+', '', text, flags=re.MULTILINE)\\n    # Supprimer les mentions et hashtags\\n    text = re.sub(r'@\\\\w+|#\\\\w+', '', text)\\n    # Supprimer la ponctuation\\n    text = re.sub(r'\\\\s+[a-zA-Z]\\\\s+', ' ', text)  # Supprimer les mots isolés\\n    text = re.sub(r'\\\\s+', ' ', text)  # Remplacer les espaces multiples par un seul\\n    # Supprimer les stopwords\\n    text = ' '.join([word for word in text.split() if word not in stop_words])\\n    return text\\n\\n# Appliquer à la colonne 'content'\\ndf['content'] = df['content'].apply(preprocess_tweet)\""
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Si ce n'est pas déjà fait, télécharger les stopwords de NLTK\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))  # Utilise le français si les tweets sont en français, sinon 'english'\n",
    "\n",
    "# Fonction de prétraitement du texte\n",
    "def preprocess_tweet(text):\n",
    "    # Convertir en minuscules\n",
    "    text = text.lower()\n",
    "    # Supprimer les URL\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    # Supprimer les mentions et hashtags\n",
    "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "    # Supprimer la ponctuation\n",
    "    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)  # Supprimer les mots isolés\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remplacer les espaces multiples par un seul\n",
    "    # Supprimer les stopwords\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "# Appliquer à la colonne 'content'\n",
    "df['content'] = df['content'].apply(preprocess_tweet)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5990ca09-e6a9-41ad-845b-e439847797dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>I should be sleep, but im not! thinking about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>@charviray Charlene my love. I miss you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>@kelcouch I'm sorry  at least it's Friday?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            content\n",
       "1          0  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2          0                Funeral ceremony...gloomy friday...\n",
       "6          0  I should be sleep, but im not! thinking about ...\n",
       "8          0            @charviray Charlene my love. I miss you\n",
       "9          0         @kelcouch I'm sorry  at least it's Friday?"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "a9dfe01f-0027-4701-b899-f78cb294e2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10374, 2000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialiser le vectoriseur avec des paramètres personnalisés\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=2000,          # Limite à 8000 mots les plus fréquents\n",
    "    max_df=0.9,                 # Exclure les termes apparaissant dans plus de 70% des documents\n",
    "         # Appliquer une transformation logarithmique sur la fréquence des termes\n",
    ")\n",
    "\n",
    "# Appliquer le vectoriseur sur la colonne 'content'\n",
    "X = vectorizer.fit_transform(df['content'])\n",
    "\n",
    "# Afficher la dimension du tableau résultant\n",
    "print(X.shape)  # (nombre d'échantillons, nombre de features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "c09ab232-a126-47a6-ab37-b89f60b0a660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 278)\t0.41353629104877854\n",
      "  (0, 1988)\t0.2883331393447881\n",
      "  (0, 1239)\t0.2228607944168102\n",
      "  (0, 1856)\t0.559437552861706\n",
      "  (0, 789)\t0.4454321019564393\n",
      "  (0, 1926)\t0.2386698401138877\n",
      "  (0, 181)\t0.35754912595039634\n"
     ]
    }
   ],
   "source": [
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "3ab12734-6b0b-4089-ab20-f577eab9ae95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle Naive Bayes: 79.23%\n",
      "Précision du modèle Naive Bayes train: 84.93%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "y = df['sentiment']  # Sentiments associés aux tweets (0 ou 1)\n",
    "\n",
    "# Diviser les données en ensemble d'entraînement et de test (80% entraînement, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Initialiser le classificateur Naive Bayes\n",
    "model = MultinomialNB()\n",
    "\n",
    "# Entraîner le modèle sur les données d'entraînement\n",
    "model.fit(X_train, y_train)\n",
    "# Faire des prédictions sur les données de test\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred2 = model.predict(X_train)\n",
    "\n",
    "# Calculer la précision du modèle\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy2 = accuracy_score(y_train, y_pred2)\n",
    "\n",
    "print(f'Précision du modèle Naive Bayes: {accuracy * 100:.2f}%')\n",
    "print(f'Précision du modèle Naive Bayes train: {accuracy2 * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "38327e82-64da-4ae0-bc4c-fa78034ae1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle Logistic Regression: 80.96%\n",
      "Précision du modèle Logistic Regression train: 86.35%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Initialiser la régression logistique avec une régularisation bayésienne (C est l'inverse de la régularisation)\n",
    "model = LogisticRegression(C=1.01, solver='lbfgs', max_iter=10000)\n",
    "\n",
    "# Entraîner le modèle sur les données d'entraînement\n",
    "model.fit(X_train, y_train)\n",
    "# Faire des prédictions sur les données de test\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred2 = model.predict(X_train)\n",
    "\n",
    "# Calculer la précision du modèle\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy2 = accuracy_score(y_train, y_pred2)\n",
    "\n",
    "print(f'Précision du modèle Logistic Regression: {accuracy * 100:.2f}%')\n",
    "print(f'Précision du modèle Logistic Regression train: {accuracy2 * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e765da86-5523-453a-83cf-354e32ba4e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SVM model\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='rbf', gamma='scale') #gaussian\n",
    "\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred2 = model.predict(X_train)\n",
    "\n",
    "# Calculer la précision du modèle\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy2 = accuracy_score(y_train, y_pred2)\n",
    "\n",
    "print(f'Précision du modèle SVM: {accuracy * 100:.2f}%')\n",
    "print(f'Précision du modèle SVM train: {accuracy2 * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "cf8076ee-2f35-499d-a970-f3d626bdabf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle K-neighbours: 52.72%\n",
      "Précision du modèle K-neighbours: 98.36%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialiser le modèle KNN\n",
    "model = KNeighborsClassifier(n_neighbors=2)\n",
    "\n",
    "# Entraîner le modèle\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred2 = model.predict(X_train)\n",
    "\n",
    "# Calculer la précision du modèle\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy2 = accuracy_score(y_train, y_pred2)\n",
    "\n",
    "print(f'Précision du modèle K-neighbours: {accuracy * 100:.2f}%')\n",
    "print(f'Précision du modèle K-neighbours: {accuracy2 * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "bc62f1fb-daec-4ba7-9ba8-a50a45d04b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle K-neighbours: 78.41%\n",
      "Précision du modèle K-neighbours: 99.87%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialiser le modèle de forêt aléatoire\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Entraîner le modèle\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred2 = model.predict(X_train)\n",
    "\n",
    "# Calculer la précision du modèle\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy2 = accuracy_score(y_train, y_pred2)\n",
    "\n",
    "print(f'Précision du modèle Forest: {accuracy * 100:.2f}%')\n",
    "print(f'Précision du modèle Forest: {accuracy2 * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "ce16d75b-fb29-4b75-bf68-8d2059d9d02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle GBC: 74.89%\n",
      "Précision du modèle GBC: 78.55%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialiser le modèle de gradient boosting\n",
    "model = GradientBoostingClassifier(n_estimators=100)\n",
    "\n",
    "# Entraîner le modèle\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred2 = model.predict(X_train)\n",
    "\n",
    "# Calculer la précision du modèle\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy2 = accuracy_score(y_train, y_pred2)\n",
    "\n",
    "print(f'Précision du modèle GBC: {accuracy * 100:.2f}%')\n",
    "print(f'Précision du modèle GBC: {accuracy2 * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87be9c40-0449-4773-99e6-9efcaca0f008",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
